{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Transforming Text For a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, you will see how scikit-learn converts raw text data into a matrix of <i>term frequency-inverse document frequency</i> (TF-IDF) features, and how to train a logistic regression model using these transformed features. You will also experiment with using different document-frequency values and see how they affect the performance of a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages. Run the code cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import the scikit-learn `LogisticRegression`, the `train_test_split()` function for splitting the data into training and test sets, and the function `roc_auc_score` to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load a 'ready-to-fit' Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a new version of the familiar Airbnb \"listings\" data set. It contains all of the numerical and binary columns we used previously, but also contains unstructured text fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.getcwd(), \"data\", \"airbnb_text_readytofit.csv.gz\")\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>neighbourhood_group_cleansed_Brooklyn</th>\n",
       "      <th>neighbourhood_group_cleansed_Manhattan</th>\n",
       "      <th>neighbourhood_group_cleansed_Queens</th>\n",
       "      <th>neighbourhood_group_cleansed_Staten Island</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <th>has_availability_True</th>\n",
       "      <th>instant_bookable_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>Beautiful, spacious skylit studio in the heart...</td>\n",
       "      <td>Centrally located in the heart of Manhattan ju...</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>A New Yorker since 2000! My passion is creatin...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.591438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole flr w/private bdrm, bath &amp; kitchen(pls r...</td>\n",
       "      <td>Enjoy 500 s.f. top floor in 1899 brownstone, w...</td>\n",
       "      <td>Just the right mix of urban center and local n...</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>Laid-back Native New Yorker (formerly bi-coast...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-4.744653</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spacious Brooklyn Duplex, Patio + Garden</td>\n",
       "      <td>We welcome you to stay in our lovely 2 br dupl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Brooklyn, New York, United States</td>\n",
       "      <td>Rebecca is an artist/designer, and Henoch is i...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Furnished Room Near B'way</td>\n",
       "      <td>Please don’t expect the luxury here just a bas...</td>\n",
       "      <td>Theater district, many restaurants around here.</td>\n",
       "      <td>Shunichi</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>I used to work for a financial industry but no...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.060696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cozy Clean Guest Room - Family Apt</td>\n",
       "      <td>Our best guests are seeking a safe, clean, spa...</td>\n",
       "      <td>Our neighborhood is full of restaurants and ca...</td>\n",
       "      <td>MaryEllen</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>Welcome to family life with my oldest two away...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578481</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                              Skylit Midtown Castle   \n",
       "1  Whole flr w/private bdrm, bath & kitchen(pls r...   \n",
       "2           Spacious Brooklyn Duplex, Patio + Garden   \n",
       "3                   Large Furnished Room Near B'way　   \n",
       "4                 Cozy Clean Guest Room - Family Apt   \n",
       "\n",
       "                                         description  \\\n",
       "0  Beautiful, spacious skylit studio in the heart...   \n",
       "1  Enjoy 500 s.f. top floor in 1899 brownstone, w...   \n",
       "2  We welcome you to stay in our lovely 2 br dupl...   \n",
       "3  Please don’t expect the luxury here just a bas...   \n",
       "4  Our best guests are seeking a safe, clean, spa...   \n",
       "\n",
       "                               neighborhood_overview    host_name  \\\n",
       "0  Centrally located in the heart of Manhattan ju...     Jennifer   \n",
       "1  Just the right mix of urban center and local n...  LisaRoxanne   \n",
       "2                                                NaN      Rebecca   \n",
       "3    Theater district, many restaurants around here.     Shunichi   \n",
       "4  Our neighborhood is full of restaurants and ca...    MaryEllen   \n",
       "\n",
       "                       host_location  \\\n",
       "0  New York, New York, United States   \n",
       "1  New York, New York, United States   \n",
       "2  Brooklyn, New York, United States   \n",
       "3  New York, New York, United States   \n",
       "4  New York, New York, United States   \n",
       "\n",
       "                                          host_about  host_is_superhost  \\\n",
       "0  A New Yorker since 2000! My passion is creatin...              False   \n",
       "1  Laid-back Native New Yorker (formerly bi-coast...              False   \n",
       "2  Rebecca is an artist/designer, and Henoch is i...              False   \n",
       "3  I used to work for a financial industry but no...              False   \n",
       "4  Welcome to family life with my oldest two away...              False   \n",
       "\n",
       "   host_has_profile_pic  host_identity_verified  host_response_rate  ...  \\\n",
       "0                  True                    True           -0.591438  ...   \n",
       "1                  True                    True           -4.744653  ...   \n",
       "2                  True                    True            0.578481  ...   \n",
       "3                  True                   False           -0.060696  ...   \n",
       "4                  True                    True            0.578481  ...   \n",
       "\n",
       "   neighbourhood_group_cleansed_Brooklyn  \\\n",
       "0                                    0.0   \n",
       "1                                    1.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    1.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Manhattan  \\\n",
       "0                                     1.0   \n",
       "1                                     0.0   \n",
       "2                                     1.0   \n",
       "3                                     1.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Queens  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Staten Island  room_type_Entire home/apt  \\\n",
       "0                                         0.0                        1.0   \n",
       "1                                         0.0                        1.0   \n",
       "2                                         0.0                        0.0   \n",
       "3                                         0.0                        0.0   \n",
       "4                                         0.0                        0.0   \n",
       "\n",
       "   room_type_Hotel room  room_type_Private room  room_type_Shared room  \\\n",
       "0                   0.0                     0.0                    0.0   \n",
       "1                   0.0                     0.0                    0.0   \n",
       "2                   0.0                     1.0                    0.0   \n",
       "3                   0.0                     1.0                    0.0   \n",
       "4                   0.0                     1.0                    0.0   \n",
       "\n",
       "   has_availability_True  instant_bookable_True  \n",
       "0                    1.0                    0.0  \n",
       "1                    1.0                    0.0  \n",
       "2                    1.0                    0.0  \n",
       "3                    1.0                    0.0  \n",
       "4                    1.0                    0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labeled Examples\n",
    "\n",
    "Let's obtain columns from our data set to create labeled examples. We will have one text feature and one label. \n",
    "The code cell below carries out the following steps:\n",
    "\n",
    "* Gets the `host_is_superhost` column from DataFrame `df` and assign it to the variable `y`. This will be our label.\n",
    "* Gets the column `description` from DataFrame `df` and assigns it to the variable `X`. This will our feature. Note that the `description` feature contains text describing the listing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27388,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['host_is_superhost'] \n",
    "X = df['description']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Beautiful, spacious skylit studio in the heart...\n",
       "1    Enjoy 500 s.f. top floor in 1899 brownstone, w...\n",
       "2    We welcome you to stay in our lovely 2 br dupl...\n",
       "3    Please don’t expect the luxury here just a bas...\n",
       "4    Our best guests are seeking a safe, clean, spa...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Labeled Examples into Training and Test Sets\n",
    "\n",
    "Let's split our data into training and test sets with 75% of the data being the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775      <b>The space</b><br />This 450 sf apartment is...\n",
       "4        Our best guests are seeking a safe, clean, spa...\n",
       "7294     I am subletting my room for the entire month o...\n",
       "26836    4 queen bedrooms mean plenty of room to share ...\n",
       "3914     Modern studio on the lower level of our histor...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.75, random_state=1234)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Implement TF-IDF Vectorizer to Transform Text\n",
    "\n",
    "A popular technique when transforming text to numerical feature vectors is to use the TF-IDF statistical measure. TF-IDF calculates how relevant a word is in a document relative to a collection of documents. It weighs words to indicate the words that are the most unique to the document and therefore can be used to represent the characteristics of the document. For example, the word \"the\" appears in many documents and therefore is not characteristic of one particular document in a collection. On the other hand, if a word appears often in one document and rarely in other documents in the collection, the word is given a higher value of importance to that one document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a simple example. We will use the scikit-learn `TfidfVectorizer` class to implement a TF-IDF vectorizer. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). First, let's import `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the values in the TF-IDF matrix that `TfidfVectorizer` produces:\n",
    "\n",
    "* <b>Row</b>: each document will be represented by a numerical vector (row) in the matrix. \n",
    "* <b>Column</b>: each column represents one word in the vocabulary, i.e. the number of words in ALL of the documents in the collection (with the exclusion of words that appear too frequently or too infrequently; scikit-learn has a list of such words to ignore by default, but you will see later that you can specify frequency thresholds to eliminate words that appear too often/little). \n",
    "    * The value in the columns are the TF-IDF scores (weights) for the word in every document in the collection (one document per row)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below transforms two \"documents.\" Run the cell below to see what the code produces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 7: \n",
      "{'my': 5, 'cat': 1, 'loves': 4, 'yarn': 6, 'blue': 0, 'have': 3, 'dog': 2}\n",
      "[[0.25969799 0.36499647 0.         0.         0.36499647 0.36499647\n",
      "  0.72999294]\n",
      " [0.44943642 0.         0.6316672  0.6316672  0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "document_collection = [\n",
    "    'My cat loves yarn. Blue yarn.',\n",
    "    'I have a blue dog.'\n",
    "]\n",
    "\n",
    "# 1. Create a TfidfVectorizer oject\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Fit the vectorizer to document_collection\n",
    "vectorizer.fit(document_collection)\n",
    "\n",
    "# 3. Print the vocabulary\n",
    "print(\"Vocabulary size {0}: \".format(len(vectorizer.vocabulary_)))\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# 4. Transform the data into numerical vectors \n",
    "resulting_matrix = vectorizer.transform(document_collection)\n",
    "\n",
    "# 5. Print the matrix\n",
    "print(resulting_matrix.todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the resulting matrix:\n",
    "\n",
    "<table>\n",
    "    <tr><th></th><th>blue</th><th>cat</th><th>dog</th><th>have</th><th>loves</th><th>my</th><th>yarn</th></tr>\n",
    "<tr><th>Document 1</th><th>0.25969799</th><th>0.36499647</th><th>0.</th><th>0.</th><th>0.36499647</th><th>0.36499647</th><th>0.72999294</th><t/tr>\n",
    "<tr><th>Document 2</th><th>0.44943642</th><th>0.</th><th>0.6316672</th><th>0.6316672</th><th>0.</th><th>0.</th><th>0.</th></tr>   \n",
    "    </table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We have 7 words in our vocabulary: 'blue', 'cat', dog', 'have', 'loves', 'my, 'yarn'. Note that scikit-learn excluded the words 'I' and 'a'. Therefore, we have 7 columns. Note that each word is considered a feature. Therefore, in this example, we have seven features.\n",
    "\n",
    "The `vectorizer.vocabulary_` attribute outputs a mapping of words to column indices: {'my': 5, 'cat': 1, 'loves': 4, 'yarn': 6, 'blue': 0, 'have': 3, 'dog': 2}. This means that the TF-IDF score (weight) for the word 'my' is contained is in the 5th column (the first column is 0) in the matrix.\n",
    "\n",
    "The table above summarizes the results of the code. Note that in our first document, the word 'dog' does not appear. Therefore, its value in the document's vector is 0. Since the word 'blue' appears in both documents, its importance is not as high for either document. Therefore, its value in both document vectors is not very high compared to other values. However, since 'dog' appears in the second document only, it has a higher importance since it is characteristic of the second document; its value in that document's vector is 0.6316672. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now transform our Airbnb feature values into numerical vectors using `TfidfVectorizer`. We will implement a TF-IDF transformation on the training and test data. Run the cell and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 23779)\t0.038561105614235314\n",
      "  (0, 23771)\t0.11589556798046946\n",
      "  (0, 23753)\t0.10098268550222658\n",
      "  (0, 23589)\t0.07414073282842239\n",
      "  (0, 23471)\t0.047515983056491795\n",
      "  (0, 23361)\t0.05155459572838163\n",
      "  (0, 23334)\t0.0742290362302789\n",
      "  (0, 23245)\t0.0704291887855407\n",
      "  (0, 23016)\t0.1658697199422041\n",
      "  (0, 22813)\t0.103512975598231\n",
      "  (0, 22441)\t0.04994977360595739\n",
      "  (0, 22338)\t0.16414868151481765\n",
      "  (0, 22141)\t0.04525268909148481\n",
      "  (0, 21956)\t0.07528502113419792\n",
      "  (0, 21830)\t0.11218926764426079\n",
      "  (0, 21785)\t0.06026807550555629\n",
      "  (0, 21615)\t0.0627539016485846\n",
      "  (0, 21501)\t0.11761714360779675\n",
      "  (0, 21441)\t0.06416906580885975\n",
      "  (0, 21362)\t0.1375436474856328\n",
      "  (0, 20747)\t0.08685863820037261\n",
      "  (0, 20591)\t0.09351951459480976\n",
      "  (0, 20519)\t0.08125780706785905\n",
      "  (0, 20501)\t0.11114219975162687\n",
      "  (0, 20280)\t0.07618672141212944\n",
      "  :\t:\n",
      "  (20540, 6684)\t0.08028542980233697\n",
      "  (20540, 5695)\t0.07745488700136696\n",
      "  (20540, 5683)\t0.12511711193936928\n",
      "  (20540, 5674)\t0.07046376746580481\n",
      "  (20540, 5551)\t0.033630104036726956\n",
      "  (20540, 5185)\t0.03810465894761226\n",
      "  (20540, 4455)\t0.09901877877684274\n",
      "  (20540, 4421)\t0.06740180562800677\n",
      "  (20540, 4323)\t0.2615343370748839\n",
      "  (20540, 4276)\t0.10773380954054361\n",
      "  (20540, 3751)\t0.17287058484772813\n",
      "  (20540, 3691)\t0.09484060124609671\n",
      "  (20540, 3690)\t0.11857587077521015\n",
      "  (20540, 3292)\t0.32150259507503276\n",
      "  (20540, 3165)\t0.03744104101418253\n",
      "  (20540, 2861)\t0.10052898982733316\n",
      "  (20540, 2828)\t0.049647648571407625\n",
      "  (20540, 2549)\t0.10019316553675903\n",
      "  (20540, 2540)\t0.031756739762757974\n",
      "  (20540, 2426)\t0.03526122727666069\n",
      "  (20540, 2372)\t0.027153975500984293\n",
      "  (20540, 2218)\t0.08508984561182216\n",
      "  (20540, 2209)\t0.0485701321997001\n",
      "  (20540, 1887)\t0.04722029785250357\n",
      "  (20540, 1818)\t0.0693047032085682\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a TfidfVectorizer oject\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Fit the vectorizer to X_train\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# 3. Transform *both* the training and test data using the fitted vectorizer and its 'transform' attribute\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit a Logistic Regression Model to the Transformed Training Data and Evaluate the Model\n",
    "The code cell below trains a logistic regression model using the TF-IDF features and computes the AUC on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on the test data: 0.7654\n",
      "The size of the feature space: 25353\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('space', 20050), ('br', 4323), ('this', 21441), ('450', 1178)]:\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a LogisticRegression model object, and fit a Logistic Regression model to the transformed training data\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 2. Make predictions on the transformed test data using the predict_proba() method and \n",
    "# save the values of the second column\n",
    "probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "# 3. Make predictions on the transformed test data using the predict() method \n",
    "class_label_predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# 4. Compute the Area Under the ROC curve (AUC) for the test data. Note that this time we are using one \n",
    "# function 'roc_auc_score()' to compute the auc rather than using both 'roc_curve()' and 'auc()' as we have \n",
    "# done in the past\n",
    "auc = roc_auc_score(y_test, probability_predictions)\n",
    "print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "# 5. Print out the size of the resulting feature space using the 'vocabulary_' attribute of the vectorizer\n",
    "len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "\n",
    "# 6. Get a glimpse of the features:\n",
    "first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check one listing's description and see if our model properly predicted whether the host is a 'superhost' or not based on the location, the amenities, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:\n",
      "\n",
      "***WE TAKE OUR GUESTS' SAFETY VERY SERIOUSLY!   We are following all recommended cleaning and sanitation protocols.<br /><br /><b>The space</b><br />Our 2 bedroom apartment is located on the first floor of a recently renovated, century-old brick townhouse.  It has wood floors throughout, exposed brick, original tin ceilings, tub/shower in bathroom, kitchen alcove, living room and two bedrooms.  Downstairs is an open plan finished basement with a washer/dryer and a Queen-sized sleeper sofa for extra sleeping space.<br /><br />We also have a lovely private backyard, and street parking if you are traveling by car.<br /><br />Located between the neighborhoods of DUMBO and Fort Greene, you are a 10 minute walk from either neighborhood with lots of shops and restaurants.  Across the street is Commodore Barry Park, Brooklyn's first park.  It was recently renovated and features an open area with lots of trees and benches directly across from the apartment, sports fields on the far side of the \n",
      "\n",
      "Prediction: Is host superhost? True\n",
      "\n",
      "Actual: Is host superhost? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Description:\\n')\n",
    "print(X_test[389])\n",
    "\n",
    "print('\\nPrediction: Is host superhost? {}\\n'.format(class_label_predictions[389]))\n",
    "\n",
    "print('Actual: Is host superhost? {}\\n'.format(y_test[389]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Experiment with Different Document Frequency Values and Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a `TfidfVectorizer` object, you can use the parameter `min_df` to specify the minimum 'document frequency.' This allows you to ignore words that have a document frequency lower than the specified value. In other words, they ignore words that occur in too few documents.\n",
    "\n",
    "The code cell below puts the code above into a loop over a range of 'document frequency' values. For each value, it fits a vectorizer specifying `ngram_range=(1,2)` (instead of the default (1,1)). Run the code and inspect the results. \n",
    "\n",
    "Note: This may take a short while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min Document Frequency Value: 1\n",
      "AUC on the test data: 0.7976\n",
      "The size of the feature space: 361588\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('space', 288068), ('br', 59038), ('this', 315196), ('450', 7085)]:\n",
      "Glimpse of first 5 stop words \n",
      "[]:\n",
      "\n",
      "Min Document Frequency Value: 10\n",
      "AUC on the test data: 0.7877\n",
      "The size of the feature space: 32902\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('space', 25748), ('br', 5754), ('this', 28492), ('450', 502)]:\n",
      "Glimpse of first 5 stop words \n",
      "['parks galore', 'mentioned above', 'knock on', 'large tastefully']:\n",
      "\n",
      "Min Document Frequency Value: 100\n",
      "AUC on the test data: 0.7631\n",
      "The size of the feature space: 4558\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('space', 3471), ('br', 767), ('this', 3881), ('apartment', 403)]:\n",
      "Glimpse of first 5 stop words \n",
      "['knock on', 'mentioned above', 'receiving basket', 'grupo de']:\n",
      "\n",
      "Min Document Frequency Value: 1000\n",
      "AUC on the test data: 0.7004\n",
      "The size of the feature space: 490\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('space', 370), ('br', 74), ('this', 413), ('apartment', 25)]:\n",
      "Glimpse of first 5 stop words \n",
      "['knock on', 'mentioned above', 'receiving basket', 'grupo de']:\n"
     ]
    }
   ],
   "source": [
    "for min_df in [1,10,100,1000]:\n",
    "    \n",
    "    print('\\nMin Document Frequency Value: {0}'.format(min_df))\n",
    "    \n",
    "    # 1. Create a TfidfVectorizer oject\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df, ngram_range=(1,2))\n",
    "\n",
    "    # 2. Fit the vectorizer to X_train\n",
    "    tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "    # 3. Transform the training and test data\n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    # 4. Create a LogisticRegression model object, and fit a Logistic Regression model to the transformed \n",
    "    # training data\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # 5. Make predictions on the transformed test data using the predict_proba() method and save \n",
    "    # the values of the second column\n",
    "    probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "    # 6. Compute the Area Under the ROC curve (AUC) for the test data.\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "    # 7. Compute the size of the resulting feature space using the 'vocabulary_' attribute of the vectorizer\n",
    "    len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "    print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "    \n",
    "    # 8. Get a glimpse of the features:\n",
    "    first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "    print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n",
    "\n",
    "    # 9: Print the first five \"stop words\" - words that we are ignoring\n",
    "    first_five_stop = list(tfidf_vectorizer.stop_words_)[1:5]\n",
    "    print('Glimpse of first 5 stop words \\n{}:'.format(first_five_stop))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis (ungraded):</b> Just as you can use the parameter `min_df` to specify the minimum 'document frequency,' you can use the parameter `max_df` to ignore words that have a document frequency higher than the specified value. Try using the parameter `max_def` and compare the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
