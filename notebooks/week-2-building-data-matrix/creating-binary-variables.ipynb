{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Binary Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.getcwd(), \"data\", \"adult.data.partial\")\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glance at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Summary Statistics by Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Columns into Binary Values Using `np.where()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "One of the typical tasks in data cleaning and feature engineering is to convert a feature or a label that has multiple categorical values into one that has a binary value. This means that instead of having multiple potential values, a feature or a label will have just two potential values.\n",
    "\n",
    "For example, let's say we have \"type of animal\" as a feature and a list of 11 potential values for animals:\n",
    "\n",
    "cats, dogs, sharks, elephants, iguanas, pigeons, humans, dolphins, mice, goldfish, hummingbirds\n",
    "\n",
    "We can group these animals into **two** categories- `mammal` and `not-mammal` - and therefore, the \"type of animal\" feature will have two potential values (rather than 11 potential values).\n",
    "\n",
    "cats, dogs, elephants, humans, dolphins, mice -> **mammal** \n",
    "\n",
    "iguanas, pigeons, goldfish, sharks, hummingbirds -> **not-mammal**\n",
    "\n",
    "\n",
    "In this exercise, we will convert one feature column in our dataset (the `workclass` column) to contain binary values.\n",
    "\n",
    "\n",
    "In the cell below, inspect the current the `workclass` column in the DataFrame `df`. Notice the different feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first 30 rows of DataFrame `df` and focus on the `workclass` column to see some of the above values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to consolidate all of the different types of employment into two groups: **self-employed** and **not self-employed**, and change the values in the `workclass` column accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Create Group 1: `Not-self-emp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `workclass` column contains the values `Self-emp-inc`and `Self-emp-not-inc` to indicate that an individiual is self-employed (these correspond to incorporated and the unincorporated self-employment).\n",
    "\n",
    "\n",
    "Note that the `workclass` column contains a number of different values for individuals who are *not* self employed ('State-gov', 'Private', 'Local-gov', 'Federal-gov', 'Without-pay').\n",
    "\n",
    "As a first step, we can group all of the \"not self employed\" values into one category - a **not self employed** category. We can change all of the `workclass` columns that contain the values 'State-gov', 'Private', 'Local-gov', 'Federal-gov', 'Without-pay' to the value `'Not-self-emp'`.\n",
    "\n",
    "Let's try this using the `np.where()` function. First, read the documentation for the `np.where()` function. Then examine and run the code below and try to understand how it works.\n",
    "\n",
    "For more information about `np.where()`, consult the online [documentation](https://numpy.org/doc/stable/reference/generated/numpy.where.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are only two values for self-employment, we can simplify our code by writing \n",
    "# NOT self employed \n",
    "\n",
    "# get all examples (rows) in which the workclass feature (column) is not self-employed\n",
    "# Note: the code below uses the Pandas logical operator ~ for NOT\n",
    "columns_not_self_employed = ~(df['workclass'] == 'Self-emp-not-inc') & ~(df['workclass'] == 'Self-emp-inc')\n",
    "\n",
    "#leave nan (null) in the dataset for now. Get all examples (rows) in which the workclass feature (column) is not null\n",
    "columns_not_null = ~(df['workclass'].isnull())  \n",
    "\n",
    "# create condition\n",
    "condition = columns_not_self_employed & columns_not_null\n",
    "\n",
    "# Use np.where() to change all of the workclass values that fulfill the specified condition to Not-self-emp\n",
    "df['workclass'] = np.where(condition, 'Not-self-emp', df['workclass'])\n",
    "\n",
    "# Inspect the data to see the changed values\n",
    "df.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to see the new  feature values for the `workclass` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we did not lose the `nan` values. Think about what would have happened had we not excluded 'NaN' values in our 'condition'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Group 2: `Self-emp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully created a `Not-self-emp` group and changed all pertinent values in column `workclass` to the value `Not-self-emp`. \n",
    "\n",
    "However, recall that our goal was to consolidate all of the different types of employment into two groups: **self-employed** and **not self-employed**\n",
    "\n",
    "Notice that we still have two values for self employment: `Self-emp-not-inc`, `Self-emp-inc`.\n",
    "\n",
    "We do not care to distinguish between the incorporated and the unincorporated self-employed examples, so we will next consolidate and change all `Self-emp-not-inc`and `Self-emp-inc` values in the `workclass` column to the value `Self-emp`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two code cells below, you will use `np.where()` to combine `Self-emp-not-inc` and `Self-emp-inc` into a single class called `Self-emp`. Note: Follow the two steps as outlined per cell in order to properly grade your work.\n",
    "\n",
    "#### Part 1:\n",
    "Create the condition and name it `condition`. `condition` will contain a compound statement joined together by the Boolean operator <b>or</b> (`|`). It will find the people who are not self employed, i.e. it will look for both the value `Self-emp-not-inc` and the value `Self-emp-inc` in the `workclass` column. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Cells\n",
    "\n",
    "The two cells below will be graded. Remove the lines \"raise NotImplementedError()\" before writing your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da5677253bbdc52017c535d5260c06fb",
     "grade": false,
     "grade_id": "cell-15a2c1ed30c10ea4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "columns_self_employed = (df['workclass'] == 'Self-emp-not-inc') | (df['workclass'] == 'Self-emp-inc')\n",
    "\n",
    "condition = columns_self_employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Check\n",
    "\n",
    "Run the cell below to test the correctness of your code above before submitting for grading. Do not add code or delete code in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e253b4678b5f7f74cd530dc76a385849",
     "grade": true,
     "grade_id": "cell-62257e9f6d5996cf",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this self-test cell to check your code; \n",
    "# do not add code or delete code in this cell\n",
    "from jn import testCondition\n",
    "\n",
    "try:\n",
    "    p, err = testCondition(df, condition)\n",
    "    print(err)\n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2:\n",
    "\n",
    "In the code cell below, use `np.where()` to combine `Self-emp-not-inc` and `Self-emp-inc` into a single class called `Self-emp`. Use the condition you created in Step 1. Follow the code pattern you have seen previously when implementing `np.where()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b4e395c197f060940428e047deaae787",
     "grade": false,
     "grade_id": "cell-590fbeaeb78029eb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df['workclass'] = np.where(condition, 'Self-emp', df['workclass'])\n",
    "\n",
    "# df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Check\n",
    "\n",
    "Run the cell below to test the correctness of your code above before submitting for grading. Do not add code or delete code in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "476f3ecd42ab882df98d2a9f10fdb73a",
     "grade": true,
     "grade_id": "cell-9e4773a4d563f1ee",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this self-test cell to check your code; \n",
    "# do not add code or delete code in this cell\n",
    "from jn import testWorkclass\n",
    "\n",
    "try:\n",
    "    p, err = testWorkclass(df)\n",
    "    print(err)\n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your results \n",
    "df['workclass'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below transforms the labels into a binary 'True' and 'False' variable, where 'True' is the label assigned to income level >50K. Run the code and inspect the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65edb418ae345b183354ac61b30fecab",
     "grade": false,
     "grade_id": "cell-ed741543afbf5447",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "condition1 = (df['label'] == '>50K')\n",
    "df['label'] = np.where(condition1, 'True', df['label'])\n",
    "\n",
    "condition2 = (df['label'] == '<=50K')\n",
    "df['label'] = np.where(condition2, 'False', df['label'])\n",
    "\n",
    "df.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Dive: Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us discuss categorical variables in a little bit more detail.<br>\n",
    "\n",
    "A categorical data variable is often more than just a variable who's value is one of two or more classes, or categories.<br>\n",
    "Sometimes the *order* of categories is meaningful, and contains some information that may be useful for analysis.<br>\n",
    "For example, we may have a dataset that contains a variable 'ice_cream_flavor' that takes five possible values: 'vanilla', 'strawberry', 'pistachio', 'chocolate', and 'mango'. In this example, there is not a natural order to the five categories. <br>\n",
    "Now consider a variable called 'portion_size' that takes on one of the three possible values: 'standard', 'double', and 'super'. In this case, the three categories are related to one another by an *ordering*. We would like for any future model we fit to this data to recognize and make use of the fact that $$standard < double < super.$$\n",
    "<br>\n",
    "\n",
    "Try to think of a variable in our dataset that should be an ordered categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One such variable would be 'education'. Let's examine the list of possible values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly an underlying order to these categories!<br>\n",
    "In general, you would have to consult the data manual to establish what the correct order is.<br>\n",
    "For this data, the true ordering would be:<br>\n",
    "    \n",
    "$$Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate.$$\n",
    "<br>\n",
    "Is this variable currently ordered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No! This variable is of type 'object'. Any future analysis in python won't recognize the underlying order of categories. \n",
    "<br> We need to transform this variable into an ordered categorical variable. Here's how.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a correctly ordered list of category names:\n",
    "edu = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '1th', '12th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', 'Some-college', 'Bachelors', 'Masters', 'Doctorate']\n",
    "# Then, use the pd.Categorical method to reassign the values of this column as a new type with awareness of the order:\n",
    "df['education'] = pd.Categorical(df['education'], ordered=True, categories=edu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now we can be sure that the order is recognized by Python. <br>\n",
    "(Note: This will come in handy when we create plots with categories on one axis.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical Variables into \"Dummy\" Variables\n",
    "\n",
    "There are many different ways we can transform our categorical data into numerical data to prepare for the model training phase. Pandas has one function that helps us transform categorical values into binary ones. It is the `pd.get_dummies()` function. Often we refer to these binary values as \"dummy\" values, or variables. Read up on the Pandas `pd.get_dummies()` function. You can consult the online [documentation](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html).\n",
    "Run the cell below to observe the results of creating dummies for all variables in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = pd.get_dummies(df)\n",
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
